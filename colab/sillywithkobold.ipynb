{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vrihatgan/SillyTavern/blob/release/colab/sillywithkobold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#There exist two colob notebooks\n",
        "#1.  Koboldcpp\n",
        "https://colab.research.google.com/github/vrihatgan/SillyTavern/blob/release/colab/sillywithkobold.ipynb\n",
        "#2.  Gemini api\n",
        "first get your gemini key from here :--> https://aistudio.google.com/app/u/2/apikey\n",
        "https://colab.research.google.com/github/vrihatgan/SillyTavern/blob/gemini/colab/sillywithgemini.ipynb"
      ],
      "metadata": {
        "id": "GXanjkBPL9La"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtmwY5Qh_2V4"
      },
      "outputs": [],
      "source": [
        "#@title Tap this if you play on Mobile { display-mode: \"form\" }\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive, then start KoboldCpp below</b><br/>\n",
        "<audio autoplay=\"\" src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" loop controls>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsUhAZBU-dHc"
      },
      "outputs": [],
      "source": [
        "#@title Tap this to run sillytavern { check box below if you want to back up on google drive } { display-mode: \"form\" }\n",
        "Model = \"https://huggingface.co/TheBloke/Noromaid-13B-v0.3-GGUF/resolve/main/noromaid-13b-v0.3.Q4_K_M.gguf\"\n",
        "use_drive_for_chat_backup = False #@param {type:\"boolean\"}\n",
        "import os\n",
        "import subprocess\n",
        "import json\n",
        "import time\n",
        "import shutil\n",
        "import threading\n",
        "import sys\n",
        "import torch\n",
        "import requests\n",
        "if not torch.cuda.is_available():\n",
        "    from IPython.display import display, Markdown\n",
        "    display(Markdown(\"<h1>NO free gpu is avilable for you at the moment</h1>\"))\n",
        "    sys.exit()\n",
        "from google.colab import drive\n",
        "os.chdir(\"/content\")\n",
        "print(\"SillyTavern brought to you by Cohee1207\")\n",
        "print(\"Colab notebook written by doctord98 with added api support by vrihatgan\")\n",
        "print(\"Please wait while I setup everything for you\")\n",
        "if use_drive_for_chat_backup:\n",
        "  drive.mount('/content/drive')\n",
        "subprocess.call(\"git clone https://github.com/vrihatgan/SillyTavern\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "src1 = '/content/SillyTavern/data/default-user/characters'\n",
        "des1 = '/content/drive/MyDrive/SillyTavern/characters'\n",
        "src2 = '/content/SillyTavern/data/default-user/chats'\n",
        "des2 = '/content/drive/MyDrive/SillyTavern/chats'\n",
        "Layers = 99\n",
        "ContextSize = 4096\n",
        "subprocess.run(\"wget -O dlfile.tmp https://kcpplinux.concedo.workers.dev && mv dlfile.tmp koboldcpp_linux\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "subprocess.run(\"chmod +x ./koboldcpp_linux\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "subprocess.run(\"apt install aria2 -y\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "print(\"downloading model\")\n",
        "subprocess.run(f\"aria2c -x 10 -o model.gguf --summary-interval=5 --download-result=default --allow-overwrite=true --file-allocation=none {Model}\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "print(\"downloading complete\")\n",
        "print(\"now loading model\")\n",
        "command = f\"./koboldcpp_linux model.gguf --usecublas 0 mmq --multiuser --gpulayers {Layers} --contextsize {ContextSize} --quiet\"\n",
        "subprocess.Popen(command, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "flag_file = \"backup_flag.txt\"\n",
        "if use_drive_for_chat_backup:\n",
        "    if os.path.exists(flag_file):\n",
        "        print(\"The code has already been executed.\")\n",
        "    else:\n",
        "\n",
        "      if not os.path.exists(des1):\n",
        "        os.makedirs(des1)\n",
        "        shutil.copytree(src1, des1, dirs_exist_ok=True)\n",
        "      else:\n",
        "        !rm -rf /content/SillyTavern/data/default-user/characters/*\n",
        "        shutil.copytree(des1, src1, dirs_exist_ok=True)\n",
        "      if not os.path.exists(des2):\n",
        "        os.makedirs(des2)\n",
        "        shutil.copytree(src2, des2, dirs_exist_ok=True)\n",
        "      else:\n",
        "        !rm -rf /content/SillyTavern/data/default-user/chats/*\n",
        "        shutil.copytree(des2, src2, dirs_exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "      def backup_thread():\n",
        "        while True:\n",
        "          try:\n",
        "            shutil.copytree(src1, des1, dirs_exist_ok=True)\n",
        "            shutil.copytree(src2, des2, dirs_exist_ok=True)\n",
        "          except Exception as e:\n",
        "            pass\n",
        "\n",
        "          time.sleep(5)\n",
        "\n",
        "      backup_thread = threading.Thread(target=backup_thread)\n",
        "      backup_thread.start()\n",
        "\n",
        "      with open(flag_file, \"w\") as f:\n",
        "        f.write(\"you don't need to run this code again just run the code below if link not working\")\n",
        "subprocess.call(\"wget https://nodejs.org/dist/v20.15.1/node-v20.15.1-linux-x64.tar.xz\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "subprocess.call(\"tar -xvf node-v20.15.1-linux-x64.tar.xz\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "subprocess.call(\"mv node-v20.15.1-linux-x64 node\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "subprocess.call(\"sudo cp -R node/* /usr/local/\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "!rm -rf node-v20.15.1-linux-x64.tar.xz node\n",
        "os.chdir(\"/content/SillyTavern\")\n",
        "subprocess.call(\"npm install\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "os.chdir('/content/')\n",
        "if not os.path.isfile('cloudflared-linux-amd64'):\n",
        "    os.system('wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64')\n",
        "    os.chmod('cloudflared-linux-amd64', 0o777)\n",
        "\n",
        "os.system('nohup ./cloudflared-linux-amd64 tunnel --url http://127.0.0.1:8000 --metrics 127.0.0.1:31337 > cf.txt 2>&1 &')\n",
        "time.sleep(4)\n",
        "\n",
        "scrape = requests.get('http://127.0.0.1:31337/metrics').text\n",
        "needle = scrape.partition('cloudflared_tunnel_user_hostnames_counts{userHostname=\"')[2].split('\"} 1')[0]\n",
        "\n",
        "if needle:\n",
        "    with open('cloudflare.log', 'w') as log:\n",
        "        log.write(\"CLOUDFLARE PROVIDES!\" + needle)\n",
        "print(needle)\n",
        "os.chdir(\"/content/SillyTavern\")\n",
        "!nohup node server.js >/dev/null 2>&1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}